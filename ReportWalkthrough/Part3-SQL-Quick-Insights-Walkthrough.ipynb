{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f2b797b-a63a-43e5-99dc-be0e8450d88d",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d02384ce-5d98-49d7-aa46-a492945a8d54",
   "metadata": {},
   "source": [
    "In this section, we use our model to extract insights from the data, focusing on five key questions:\n",
    "\n",
    "1. How have house prices changed each year in nominal terms, adjusted for CPIH (inflation), and in relation to the national median salary?\n",
    "\n",
    "2. How has housing affordability changed over time in each region? Which regions are the most and least affordable in each year?\n",
    "\n",
    "3. How have the prices of different house types evolved relative to one another over time?\n",
    "\n",
    "4. What is the national trend in the total number of housing sales?\n",
    "\n",
    "5. How are yearly sales distributed across the months, and do any seasonal trends exist?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b8f6c7-5837-4afd-9840-34aca2a5c155",
   "metadata": {},
   "source": [
    "For each question, we will write a query to extract the relevant data and then export the results to Power BI for quick visualisation. The process of exporting and creating the visualisations will be demonstrated once, as we will explore Power BI in more detail in the next and final section (when creating a report)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4974d820-d325-4f36-97dd-2e8336b1a348",
   "metadata": {},
   "source": [
    "# Q1: How have house prices changed each year in nominal terms, adjusted for CPIH (inflation), and in relation to the national median salary?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e13522c-503d-42e8-bc04-e948ed1482d2",
   "metadata": {},
   "source": [
    "First, we join the national housing data, CPIH data and national median salary data to the dates dimension table on the relevant columns. This produces the following:\n",
    "\n",
    "![output of query joining national housing data, cpih data and national median salary data](documentation_images\\joining-national-house-cpi-salary.png)\n",
    "\n",
    "For this analysis, we make use of the `year`, `average_price`, `index_normed` and `MedianSalary` columns. \n",
    "\n",
    "We will group by the `year` and take the average (mean) of the `average_price`, `average_price`/`index_normed` (i.e. CPIH adjusted average price), and `average_price`/`MedianSalary` (i.e. average price to median salary ratio) columns. \n",
    "\n",
    "Note that it could be argued that this method of taking the mean is slightly inaccurate, due to the fact that we are not weighting by monthly sales volume. However, sales volume is not available until 2005, and moreover, the sales volumes Y-on-Y are relatively similar, so using a \"simple mean\" (i.e. an unweighted average) will not affect the general trend. \n",
    "\n",
    "```sql\n",
    "with HouseCPIHSalaryNationalData as (\n",
    "    select\n",
    "        d.year,\n",
    "        h.average_price,\n",
    "        c.index_normed,\n",
    "        ms.MedianSalary\n",
    "    from datesdim d\n",
    "\tjoin housepricesnational h on d.date = h.date\n",
    "\tjoin cpih c on d.month = c.month and d.year = c.year\n",
    "\tjoin mediansalarynational ms on d.year = ms.year\n",
    ")\n",
    "select\n",
    "    year,\n",
    "    avg(average_price) as average_price,\n",
    "    round(avg(average_price / index_normed),2) as average_price_cpih_adjusted,\n",
    "    round(avg(average_price / MedianSalary),2) as average_price_to_median_salary_ratio\n",
    "from HouseCPIHSalaryNationalData\n",
    "group by year\n",
    "order by year;\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "![output of query answering Q1](documentation_images\\Q1SQLOutput.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0dc662-aa57-41f2-8d29-0f92fa22cf36",
   "metadata": {},
   "source": [
    "## Creating a visual with the output of the SQL query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec664a7c-1534-41d0-ae63-ae00212c2fe9",
   "metadata": {},
   "source": [
    "To create a visual with the information from the output, we export the output and load it into Power BI. \n",
    "\n",
    "This process is only given for this question (for Q2-Q5, we will just give the output) as there's nothing really to do in Power BI, other than drag and drop fields, and we will discuss Power BI more in the next section when we create a report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33d4b58-3308-469a-a4ca-91a3e2f0db49",
   "metadata": {},
   "source": [
    "We use the `Export` button in MySQL to export the output as a CSV file:\n",
    "\n",
    "![THe export recordset button](documentation_images/ExportRecordSet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738f1a27-36de-486a-a656-f25759e23beb",
   "metadata": {},
   "source": [
    "\n",
    "In Power BI, start by selecting Get data > Text/CSV to load the dataset. Once imported, the data will be available in the Data pane.\n",
    "\n",
    "![loading the data in PowerBI](documentation_images/LoadCSVPowerBI.png)\n",
    "\n",
    "Next, create a line chart, adding the average house price and CPIH-adjusted average house price to the y-axis section. Note that we place the average price-to-median salary ratio on a secondary y-axis, as it has a different scale.\n",
    "\n",
    "We then modify the y-axis ranges so that both lines begin at the same height, allowing for an easy visual comparison.\n",
    "\n",
    "Then, line thickness is adjusted, and the average price line is changed to a dashed line, as the primary focus of this visual is the comparison between the CPIH adjusted price and the price-to-salary ratio. \n",
    "\n",
    "Finally, the title, axes labels, and legend labels are changed to ensure the chart is clear and informative. Data labels for key values are also added."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21794ea-83c1-4e24-98b5-12eaed0a1448",
   "metadata": {},
   "source": [
    "![formatting the visual](documentation_images/VisualFormattingPowerBI.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e94c0a5-0208-475e-8f45-dfb3af930a63",
   "metadata": {},
   "source": [
    "The result is the following visualisation:\n",
    "\n",
    "![formatting the visual](documentation_images/Q1PowerBIVisual.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a4fcb0-1f69-46f7-82c6-711fe1435cf8",
   "metadata": {},
   "source": [
    "# Q2: How has housing affordability changed over time in each region? Which regions are the most and least affordable in each year?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbc0205-22d2-4f4e-ae29-09bb7af98ea3",
   "metadata": {},
   "source": [
    "To answer this question, we will use the `housepricesregional` and `mediansalaryregional` tables. \n",
    "\n",
    "We first perform a cross join with the DatesDim and RegionsDim tables, creating a dimension table with (date, region) pairs. \n",
    "\n",
    "Then, we (inner) join the `housepricesregional` table on the date and region columns, and also (inner) join the `mediansalaryregional` table on the region and year columns. (Recall that house prices are recorded monthly and median salaries are recorded annually.)\n",
    "\n",
    "The query and output are as follows:\n",
    "\n",
    "```sql\n",
    "with date_region_pairs as (\n",
    "    select d.date, d.year, r.region\n",
    "    from datesdim d\n",
    "    cross join regionsdim r\n",
    ")\n",
    "select dr.date, dr.year, dr.region, h.average_price, m.salary\n",
    "from date_region_pairs dr\n",
    "inner join housepricesregional h on dr.date = h.date and dr.region = h.region\n",
    "inner join mediansalaryregional m on dr.region = m.region and dr.year = m.year;\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "![output of query finding average house price and median salary per (date, region) pair](documentation_images/Q2IntermediateSQLOutput.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb2e937-bb72-4aa6-8814-fab81976d7fc",
   "metadata": {},
   "source": [
    "Next, we wrap the select query in a CTE (note, we drop `dr.date` as we only included it for clarity in the above output - it is not actually needed). Then we calculate the \"affordability index\" (`average_price` / `salary`), group by `year` and `region`. We output and export this query and create a visual in Power BI (which we won't walk through, as the workflow is very similar to that in Q1). \n",
    "\n",
    "Once again, we opt for a simple average rather than one weighted by monthly sales volume, for much the same reasons as we did in Q1. \n",
    "\n",
    "The query, output and visualisation are as follows:\n",
    "\n",
    "```sql\n",
    "with date_region_pairs as (\n",
    "    select d.date, d.year, r.region\n",
    "    from datesdim d\n",
    "    cross join regionsdim r\n",
    "),\n",
    "year_region_price_salary as (\n",
    "select dr.year, dr.region, h.average_price, m.salary\n",
    "from date_region_pairs dr\n",
    "inner join housepricesregional h on dr.date = h.date and dr.region = h.region\n",
    "inner join mediansalaryregional m on dr.region = m.region and dr.year = m.year\n",
    ")\n",
    "select year, region, avg(average_price / salary) as affordability_index \n",
    "from year_region_price_salary \n",
    "group by year, region;\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "![affordability trends SQL output](documentation_images/Q2AffordabilitySQLOutput.png)\n",
    "\n",
    "Visualisation:\n",
    "\n",
    "![affordability trends visualisation, made in PowerBI](documentation_images/Q2PowerBIVisual.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5e577a-9ed0-4e7a-80de-a842d8d02630",
   "metadata": {},
   "source": [
    "To answer the second part of the question (namely, which regions are the least and most affordable in each year), we wrap the select statement from the previous query in a CTE and apply the windows function, `rank()`, over the year, ordered by the affordability index. The query and output are as follows:\n",
    "\n",
    "```sql\n",
    "with date_region_pairs as (\n",
    "    select d.date, d.year, r.region\n",
    "    from datesdim d\n",
    "    cross join regionsdim r\n",
    "),\n",
    "year_region_price_salary as (\n",
    "select dr.year, dr.region, h.average_price, m.salary\n",
    "from date_region_pairs dr\n",
    "inner join housepricesregional h on dr.date = h.date and dr.region = h.region\n",
    "inner join mediansalaryregional m on dr.region = m.region and dr.year = m.year\n",
    "),\n",
    "affordability_by_year_region as (\n",
    "select year, region, avg(average_price / salary) as affordability_index \n",
    "from year_region_price_salary \n",
    "group by year, region\n",
    "),\n",
    "ranked_affordability as (\n",
    "select year,region, rank() over (partition by year order by affordability_index) as affordability_rank\n",
    "from affordability_by_year_region\n",
    ")\n",
    "select year,region, if(affordability_rank = 1, \"Most affordable\", \"Least affordable\") as Affordability\n",
    "from ranked_affordability\n",
    "where affordability_rank = 1 or affordability_rank = 12;\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "![most and least affordable region for each year](documentation_images/Q2SQLOutputPart2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cc20a1-124e-4dc8-8400-e12dfc8c005e",
   "metadata": {},
   "source": [
    "This output would benefit greatly from a pivot on the `Affordability` column. We do this in PowerBI via a matrix visualisation. This gives the following:\n",
    "\n",
    "![matrix visualisation showing the least and most affordable region in each year](documentation_images/Q2PowerBIVisualPart2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1458e80d-7e7f-44f9-ac24-2f0bbef4e318",
   "metadata": {},
   "source": [
    "# Q3: How have the prices of different house types evolved relative to one another over time?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc3ab08-f99d-486a-9c5c-4bf6fec03ea4",
   "metadata": {},
   "source": [
    "For this question, we return to the national house price data in the table, `housepricesnational`. \n",
    "\n",
    "We will perform an (inner) join between this table and the `DatesDim` table.\n",
    "\n",
    "We then group the results by year and calculate the average (mean) sale price for each housing type.\n",
    "\n",
    "Finally, we filter out rows which have null values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d470938a-346d-407c-9acd-428a70509f00",
   "metadata": {},
   "source": [
    "Once again, we use a simple average (i.e. we don't weight based on monthly sales), just as we did when answering Q1 and Q2. Moreover, we do not have a breakdown for sales volume for each house type, so even if we wanted to perform a weighted average, we couldn't. Therefore, the simple average will do.\n",
    "\n",
    "The query and output are as follows:\n",
    "\n",
    "```sql\n",
    "select d.year, \n",
    "\t   avg(h.detached_avg) as detached, \n",
    "\t   avg(h.semi_avg) as semidetached, \n",
    "\t   avg(h.terraced_avg) as terraced, \n",
    "\t   avg(h.flat_avg) as flat\n",
    "from datesdim d \n",
    "join housepricesnational h on d.date = h.date\n",
    "group by d.year\n",
    "having avg(h.detached_avg) is not null \n",
    "   and avg(h.semi_avg) is not null \n",
    "   and avg(h.terraced_avg) is not null \n",
    "   and avg(h.flat_avg) is not null;\n",
    "```\n",
    "\n",
    "![average price by type for each year](documentation_images/Q3SQLOutput.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d86c77-63f1-4fa3-a43e-aa39a9bcf2c6",
   "metadata": {},
   "source": [
    "A suitable visualization for this data is a 100% stacked area chart, as this will allow for a clear comparison of the average prices relative to eachother. The visualisation is as follows:\n",
    "\n",
    "![matrix visualisation showing the distribution of average prices of different types of houses from 2005 to 2024](documentation_images/Q3PowerBIVisual.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0bf68b-27a9-48d2-b445-b3fe44f03415",
   "metadata": {},
   "source": [
    "# Q4: What are the regional trends in the total number of housing sales?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a30581c-aae3-466c-a2a3-70c72234245d",
   "metadata": {},
   "source": [
    "For this question, we (inner) join the `DatesDim` table and the `housepricesregional` table on the `date` column, and select the columns `DatesDim.year`, `region` and `sales_volume`.\n",
    "\n",
    "We then group by `year` and `region`, and find the sum of `sales_volume`. \n",
    "\n",
    "The query and output are as follows:\n",
    "\n",
    "```sql\n",
    "select d.year, h.region, sum(h.sales_volume)\n",
    "from DatesDim d\n",
    "join housepricesregional h on d.date = h.date\n",
    "group by d.year, h.region\n",
    "having sum(h.sales_volume) is not null;\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "![output of query to find the total sales volume by region and year](documentation_images/Q4SQLOutput.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cb66ae-a95c-4e40-af72-f89de47769b5",
   "metadata": {},
   "source": [
    "For the visualisation, we create a stacked area chart in Power BI. It is as follows:\n",
    "\n",
    "![stacked area chart showing the total number of annual housing sales per region](documentation_images/Q4PowerBIVisual.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf05415-430c-497a-8f15-5f5ae456625a",
   "metadata": {},
   "source": [
    "# Q5: How are yearly sales distributed across the months, and do any seasonal trends exist?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e56ae88-2470-4ae6-b557-4af8e5c4585d",
   "metadata": {},
   "source": [
    "For our last question (and perhaps the easiest to query), we (inner) join the `DatesDim` dimension table to the `housepricesnational` table and simply select the `year`, `month` and `sales_volume` columns. \n",
    "\n",
    "As part of the query, we create a column with the abbreviated month name. This is for the sake of the associated visualisation. We keep the `month` column around (containing numbers from 1 to 12) as this can be used as a \"helper sort column\" to ensure the abbreviated month names are sorted chronologically (as opposed to alphabetically, which is the standard sorting order for text-based columns).\n",
    "\n",
    "Moreover, December 2024 is missing data, and as we are looking at monthly distributions over each year, we must exclude the 2024 data.\n",
    "\n",
    "The query and output are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05606b9-3db9-49dc-b49e-d435f5b5b7ed",
   "metadata": {},
   "source": [
    "```sql\n",
    "select d.year, \n",
    "d.month, \n",
    "date_format(date(concat('2000-', d.month, '-01')), '%b') AS month_name_abbreved, \n",
    "h.sales_volume\n",
    "from DatesDim d\n",
    "join housepricesnational h on d.date = h.date\n",
    "where h.sales_volume is not null and d.year < 2024;\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "![number of house sales per (month,year) nationally](documentation_images/Q5SQLOutput.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a196fb-e631-43d2-bb56-e62c67ae5214",
   "metadata": {},
   "source": [
    "Once again, the visual of choice with PowerBI is a stacked area chart. It is as follows:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539eac47-8edb-4adc-bb63-19c918d0d033",
   "metadata": {},
   "source": [
    "![stacked area chart showing the trend of total number of housing sales per month](documentation_images/Q5PowerBIVisual.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
